#!/usr/bin/env python3
"""
ç¨‹å¼ç¢¼å“è³ªåˆ†æ CLI

ç”¨æ³•ï¼š
  python analyze.py <command> /path/to/project [args]

åŸºç¤å‘½ä»¤ï¼š
  ls          - åˆ—å‡ºç›®éŒ„å…§å®¹ï¼ˆå¦‚: ls src/ï¼‰
  read        - è®€å–æª”æ¡ˆå…§å®¹ï¼ˆå¦‚: read src/main.pyï¼‰
  grep        - æœå°‹æª”æ¡ˆå…§å®¹ï¼ˆå¦‚: grep . "pattern"ï¼‰

ç´¢å¼•å‘½ä»¤ï¼š
  map         - ç”¢ç”Ÿ PROJECT_MAPï¼ˆæª”æ¡ˆå±¤ç´šï¼‰
  outline     - ç”¢ç”Ÿå°ˆæ¡ˆå¤§ç¶±ï¼ˆç°¡æ½”ç‰ˆï¼‰
  symbols     - ç”¢ç”Ÿ Symbol ç´¢å¼•ï¼ˆå‡½æ•¸/é¡åˆ¥å±¤ç´šï¼‰
  search      - æœå°‹æª”æ¡ˆï¼ˆå¦‚: search . paymentï¼‰
  find        - æœå°‹å‡½æ•¸/é¡åˆ¥ï¼ˆå¦‚: find . topUpï¼‰

åˆ†æå‘½ä»¤ï¼š
  complexity  - è¤‡é›œåº¦åˆ†æï¼ˆæ‰¾å‡ºéåº¦è¤‡é›œçš„å‡½æ•¸ï¼‰
  coverage    - æ¸¬è©¦è¦†è“‹åˆ†æï¼ˆæ‰¾å‡ºæ²’æœ‰æ¸¬è©¦çš„æ¨¡çµ„ï¼‰
  duplicates  - é‡è¤‡ç¢¼åµæ¸¬ï¼ˆæ‰¾å‡º copy-paste çš„ç¨‹å¼ç¢¼ï¼‰
  api         - API æ ¼å¼ä¸€è‡´æ€§æª¢æŸ¥
  security    - å®‰å…¨æƒæ
  all         - åŸ·è¡Œæ‰€æœ‰åˆ†æ
"""

import sys
import json
import re
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / "src"))

from analyzer.complexity import ComplexityAnalyzer
from analyzer.coverage import CoverageAnalyzer
from analyzer.duplicates import DuplicateDetector
from analyzer.api_consistency import APIConsistencyChecker
from analyzer.security import SecurityScanner
from mapper.project_map import ProjectMapGenerator, quick_search
from mapper.symbol_index import SymbolIndexer, search_symbol

# å¿½ç•¥çš„ç›®éŒ„
IGNORE_DIRS = {
    'node_modules', '__pycache__', '.git', 'dist', 'build',
    '.venv', 'venv', '.pytest_cache', '.mypy_cache', '.flyto-index',
    'vendor', 'static', '.next', '.nuxt', 'coverage'
}

# æ”¯æ´çš„å‰¯æª”å
CODE_EXTENSIONS = {
    '.py', '.js', '.ts', '.jsx', '.tsx', '.vue',
    '.java', '.go', '.rs', '.rb', '.php',
    '.c', '.cpp', '.h', '.hpp', '.cs',
    '.json', '.yaml', '.yml', '.toml', '.md'
}


def cmd_ls(target_path: Path):
    """åˆ—å‡ºç›®éŒ„å…§å®¹"""
    if not target_path.is_dir():
        print(f"Error: {target_path} is not a directory")
        return

    print(f"\n{'='*70}")
    print(f"Directory: {target_path}")
    print(f"{'='*70}\n")

    dirs = []
    files = []

    for item in sorted(target_path.iterdir()):
        if item.name.startswith('.') and item.name not in {'.env.example', '.gitignore'}:
            continue
        if item.is_dir():
            if item.name not in IGNORE_DIRS:
                dirs.append(item)
        else:
            files.append(item)

    # é¡¯ç¤ºç›®éŒ„
    if dirs:
        print("Directories:")
        for d in dirs:
            count = sum(1 for _ in d.rglob('*') if _.is_file())
            print(f"  ğŸ“ {d.name}/ ({count} files)")
        print()

    # é¡¯ç¤ºæª”æ¡ˆ
    if files:
        print("Files:")
        for f in files:
            size = f.stat().st_size
            if size < 1024:
                size_str = f"{size} B"
            elif size < 1024 * 1024:
                size_str = f"{size // 1024} KB"
            else:
                size_str = f"{size // (1024 * 1024)} MB"
            print(f"  ğŸ“„ {f.name} ({size_str})")

    print(f"\nTotal: {len(dirs)} directories, {len(files)} files")


def cmd_read(file_path: Path):
    """è®€å–æª”æ¡ˆå…§å®¹"""
    if not file_path.is_file():
        print(f"Error: {file_path} is not a file")
        return

    print(f"\n{'='*70}")
    print(f"File: {file_path}")
    print(f"{'='*70}\n")

    try:
        content = file_path.read_text(encoding='utf-8')
    except UnicodeDecodeError:
        print("Error: Binary file, cannot display")
        return

    lines = content.split('\n')
    total_lines = len(lines)

    # é¡¯ç¤ºè¡Œè™Ÿ
    width = len(str(total_lines))
    for i, line in enumerate(lines, 1):
        print(f"{i:>{width}}â”‚ {line}")

    print(f"\n{'='*70}")
    print(f"Total: {total_lines} lines, {len(content)} characters")


def cmd_grep(project_path: Path, pattern: str = None):
    """æœå°‹æª”æ¡ˆå…§å®¹"""
    if not pattern:
        if len(sys.argv) > 3:
            pattern = sys.argv[3]
        else:
            print("Usage: python analyze.py grep /path/to/project <pattern>")
            print("Example: python analyze.py grep . 'def.*async'")
            print("Example: python analyze.py grep . 'TODO|FIXME'")
            return

    print(f"\n{'='*70}")
    print(f"Grep: '{pattern}' in {project_path.name}")
    print(f"{'='*70}\n")

    try:
        regex = re.compile(pattern, re.IGNORECASE)
    except re.error as e:
        print(f"Error: Invalid regex pattern - {e}")
        return

    matches = []
    files_searched = 0

    def should_skip(path: Path) -> bool:
        for part in path.parts:
            if part in IGNORE_DIRS:
                return True
        return False

    for file_path in project_path.rglob('*'):
        if not file_path.is_file():
            continue
        if should_skip(file_path):
            continue
        if file_path.suffix not in CODE_EXTENSIONS:
            continue

        files_searched += 1

        try:
            content = file_path.read_text(encoding='utf-8')
        except (UnicodeDecodeError, PermissionError):
            continue

        for line_num, line in enumerate(content.split('\n'), 1):
            if regex.search(line):
                rel_path = file_path.relative_to(project_path)
                matches.append({
                    'file': str(rel_path),
                    'line': line_num,
                    'content': line.strip()[:100]
                })

    if not matches:
        print(f"No matches found (searched {files_searched} files)")
        return

    # æŒ‰æª”æ¡ˆåˆ†çµ„é¡¯ç¤º
    current_file = None
    for m in matches[:100]:  # é™åˆ¶é¡¯ç¤º 100 ç­†
        if m['file'] != current_file:
            current_file = m['file']
            print(f"\n{current_file}:")
        print(f"  {m['line']:>4}â”‚ {m['content']}")

    print(f"\n{'='*70}")
    print(f"Found {len(matches)} matches in {files_searched} files")
    if len(matches) > 100:
        print(f"(showing first 100)")


def analyze_complexity(project_path: Path):
    """åˆ†æè¤‡é›œåº¦"""
    analyzer = ComplexityAnalyzer(project_path)
    report = analyzer.analyze()
    analyzer.print_report(report)
    return report


def analyze_coverage(project_path: Path):
    """åˆ†ææ¸¬è©¦è¦†è“‹"""
    analyzer = CoverageAnalyzer(project_path)
    report = analyzer.analyze()
    analyzer.print_report(report)
    return report


def analyze_duplicates(project_path: Path):
    """åˆ†æé‡è¤‡ç¢¼"""
    detector = DuplicateDetector(project_path, min_lines=6)
    report = detector.analyze()
    detector.print_report(report)
    return report


def analyze_api(project_path: Path):
    """åˆ†æ API ä¸€è‡´æ€§"""
    checker = APIConsistencyChecker(project_path)
    report = checker.analyze()
    checker.print_report(report)
    return report


def analyze_security(project_path: Path):
    """å®‰å…¨æƒæ"""
    scanner = SecurityScanner(project_path)
    report = scanner.analyze()
    scanner.print_report(report)
    return report


def generate_map(project_path: Path):
    """ç”¢ç”Ÿ PROJECT_MAP"""
    generator = ProjectMapGenerator(project_path)
    project_map = generator.generate()

    # è¼¸å‡ºåˆ°æª”æ¡ˆ
    output_dir = project_path / ".flyto-index"
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / "PROJECT_MAP.json"
    output_file.write_text(json.dumps(project_map, indent=2, ensure_ascii=False))

    print(f"\n{'='*70}")
    print(f"PROJECT_MAP Generated: {project_path.name}")
    print(f"{'='*70}")
    print(f"\nTotal files: {project_map['total_files']}")
    print(f"Categories: {len(project_map['categories'])}")
    print(f"\nSaved to: {output_file}")

    # é¡¯ç¤ºåˆ†é¡çµ±è¨ˆ
    print(f"\n{'='*70}")
    print("Categories:")
    print(f"{'='*70}")
    for cat, paths in sorted(project_map["categories"].items(), key=lambda x: -len(x[1])):
        print(f"  [{cat}] {len(paths)} files")

    return project_map


def generate_outline(project_path: Path):
    """ç”¢ç”Ÿå°ˆæ¡ˆå¤§ç¶±"""
    generator = ProjectMapGenerator(project_path)
    outline = generator.generate_outline()

    # è¼¸å‡ºåˆ°æª”æ¡ˆ
    output_dir = project_path / ".flyto-index"
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / "OUTLINE.md"
    output_file.write_text(outline)

    print(outline)
    print(f"\n---\nSaved to: {output_file}")

    return outline


def search_files(project_path: Path, query: str = None):
    """æœå°‹æª”æ¡ˆ"""
    if not query:
        if len(sys.argv) > 3:
            query = " ".join(sys.argv[3:])
        else:
            print("Usage: python analyze.py search /path/to/project <query>")
            print("Example: python analyze.py search . payment auth")
            return

    results = quick_search(project_path, query)

    print(f"\n{'='*70}")
    print(f"Search Files: '{query}' in {project_path.name}")
    print(f"{'='*70}")

    if not results:
        print("\nNo results found")
        return

    print(f"\nFound {len(results)} files:\n")

    for i, r in enumerate(results, 1):
        print(f"{i}. {r['path']}")
        print(f"   Purpose: {r['purpose']}")
        print(f"   Category: [{r['category']}]")
        if r['exports']:
            print(f"   Exports: {', '.join(r['exports'][:5])}")
        print()

    return results


def generate_symbols(project_path: Path):
    """ç”¢ç”Ÿ Symbol ç´¢å¼•"""
    indexer = SymbolIndexer(project_path)
    index = indexer.build_index()

    # è¼¸å‡ºåˆ°æª”æ¡ˆ
    output_dir = project_path / ".flyto-index"
    output_dir.mkdir(exist_ok=True)
    output_file = output_dir / "SYMBOL_INDEX.json"
    output_file.write_text(json.dumps(index, indent=2, ensure_ascii=False))

    print(f"\n{'='*70}")
    print(f"Symbol Index Generated: {project_path.name}")
    print(f"{'='*70}")
    print(f"\nTotal symbols: {index['total_symbols']}")
    print(f"Classes: {len(index['classes'])}")
    print(f"Functions: {len(index['functions'])}")
    print(f"Files indexed: {len(index['by_file'])}")
    print(f"\nSaved to: {output_file}")

    # é¡¯ç¤ºä¸€äº›çµ±è¨ˆ
    print(f"\n{'='*70}")
    print("Top Classes (by method count):")
    print(f"{'='*70}")
    sorted_classes = sorted(
        index['classes'].items(),
        key=lambda x: len(x[1].get('methods', [])),
        reverse=True
    )[:10]
    for name, info in sorted_classes:
        method_count = len(info.get('methods', []))
        print(f"  {name}: {method_count} methods ({info['file']}:{info['line']})")

    return index


def find_symbol(project_path: Path, query: str = None):
    """æœå°‹å‡½æ•¸/é¡åˆ¥"""
    if not query:
        if len(sys.argv) > 3:
            query = " ".join(sys.argv[3:])
        else:
            print("Usage: python analyze.py find /path/to/project <symbol_name>")
            print("Example: python analyze.py find . topUp")
            print("Example: python analyze.py find . PaymentService")
            return

    results = search_symbol(project_path, query)

    print(f"\n{'='*70}")
    print(f"Find Symbol: '{query}' in {project_path.name}")
    print(f"{'='*70}")

    if not results:
        print("\nNo symbols found")
        return

    print(f"\nFound {len(results)} symbols:\n")

    for i, r in enumerate(results, 1):
        location = f"{r['file']}:{r['line']}"
        if r['parent']:
            print(f"{i}. {r['parent']}.{r['name']} ({r['kind']})")
        else:
            print(f"{i}. {r['name']} ({r['kind']})")
        print(f"   Location: {location}")
        print()

    return results


def analyze_all(project_path: Path):
    """åŸ·è¡Œæ‰€æœ‰åˆ†æ"""
    print(f"\n{'#'*70}")
    print(f"# Full Analysis: {project_path.name}")
    print(f"{'#'*70}")

    results = {}

    print("\n[1/5] Complexity Analysis...")
    results["complexity"] = analyze_complexity(project_path)

    print("\n[2/5] Test Coverage Analysis...")
    results["coverage"] = analyze_coverage(project_path)

    print("\n[3/5] Duplicate Code Analysis...")
    results["duplicates"] = analyze_duplicates(project_path)

    print("\n[4/5] API Consistency Check...")
    results["api"] = analyze_api(project_path)

    print("\n[5/5] Security Scan...")
    results["security"] = analyze_security(project_path)

    # ç¸½çµ
    print(f"\n{'#'*70}")
    print("# SUMMARY")
    print(f"{'#'*70}")

    print(f"\n  Complex functions: {len(results['complexity'].complex_functions)}")
    print(f"  Test coverage: {results['coverage'].coverage_rate:.1f}%")
    print(f"  Duplicate blocks: {len(results['duplicates'].duplicate_blocks)}")
    print(f"  API issues: {len(results['api'].issues)}")
    print(f"  Security issues: {len(results['security'].issues)} (critical: {results['security'].critical_count})")

    return results


def main():
    if len(sys.argv) < 3:
        print(__doc__)
        sys.exit(1)

    command = sys.argv[1]
    target_path = Path(sys.argv[2]).resolve()

    if not target_path.exists():
        print(f"Error: {target_path} not found")
        sys.exit(1)

    # åŸºç¤å‘½ä»¤ï¼ˆæ“ä½œæª”æ¡ˆ/ç›®éŒ„ï¼‰
    basic_commands = {
        "ls": cmd_ls,
        "read": cmd_read,
        "grep": cmd_grep,
    }

    # å°ˆæ¡ˆå‘½ä»¤ï¼ˆæ“ä½œå°ˆæ¡ˆç›®éŒ„ï¼‰
    project_commands = {
        "map": generate_map,
        "outline": generate_outline,
        "symbols": generate_symbols,
        "search": search_files,
        "find": find_symbol,
        "complexity": analyze_complexity,
        "coverage": analyze_coverage,
        "duplicates": analyze_duplicates,
        "api": analyze_api,
        "security": analyze_security,
        "all": analyze_all,
    }

    all_commands = {**basic_commands, **project_commands}

    if command not in all_commands:
        print(f"Unknown command: {command}")
        print(f"Available: {', '.join(all_commands.keys())}")
        sys.exit(1)

    all_commands[command](target_path)


if __name__ == "__main__":
    main()
